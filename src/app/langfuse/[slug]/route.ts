// https://nextjs.org/docs/app/api-reference/functions/next-response
// https://nextjs.org/docs/app/building-your-application/routing/route-handlers
// https://nextjs.org/docs/app/api-reference/file-conventions/route
import { type NextRequest, NextResponse } from 'next/server';
import { Langfuse } from 'langfuse';
import type { LlmCallCountData } from '@/types/chart_types';

const langfuse = new Langfuse({
    publicKey: process.env.LANGFUSE_PUBLIC_KEY || '',
    secretKey: process.env.LANGFUSE_SECRET_KEY || '',
    baseUrl: process.env.LANGFUSE_BASE_URL || '',
});

const options: Intl.DateTimeFormatOptions = {
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit',
    timeZone: 'Asia/Seoul',
    hour12: false,
};

const formatTime = (dateString: string) => {
    const date = new Date(dateString);
    return new Intl.DateTimeFormat('ko-KR', options).format(date);
};

export async function GET(
    request: NextRequest,
    { params }: { params: Promise<{ slug: string }> },
) {
    // const pathName: string = request.nextUrl.pathname;
    const searchParams: URLSearchParams = request.nextUrl.searchParams;

    /* 
        queryë¡œ ë°›ì•„ì„œ í˜ì´ì§€ë§ˆë‹¤ í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ í•¨.

        ğŸ”°â—to doâ—ğŸ”°
        -> í”„ë¡ íŠ¸ì—ì„œ UIë¡œ ë°›ì•„ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼í•¨
        -> í”„ë¡ íŠ¸ì—ì„œë„ langfuse api ì‚¬ìš©í•´ì•¼í•¨
    */
    const name: string = searchParams.get('name') || 'RUNE';
    const userId: string = searchParams.get('userId') || 'woongsik';
    const specificTraceId: string | null = searchParams.get('traceId');

    // ê·¸ë˜í”„ í‘œì‹œë¥¼ ìœ„í•´ í•„ìš”í•œ ë³€ìˆ˜ë“¤
    // ğŸ’¥ ëª¨ë¸ ì¶”ê°€ë˜ë©´ ìˆ˜ì •í•´ì•¼ í•¨.ğŸ’¥
    const llmModel: Array<string> = ['claude-3-5-sonnet-20241022', 'llama3.3'];
    let [allLatency, startTime, endTime]: [number, string, string] = [
        0,
        '',
        '',
    ];
    const llmLatency: [Array<number>, Array<number>] = [[], []];
    // const llmTime: [Array<string>, Array<string>] = [[], []];

    const llmInputTokenCount: [Array<number>, Array<number>] = [[], []];
    const llmOutputTokenCount: [Array<number>, Array<number>] = [[], []];
    const llmToktalTokenCount: [Array<number>, Array<number>] = [[], []];
    let llmCallCount: [number, number] = [0, 0];

    // https://js.reference.langfuse.com/classes/langfuse.Langfuse.html api ì°¸ê³ í•˜ì—¬ ì‘ì„±
    try {
        let traceSelected: any;
        if (specificTraceId) {
            const trace = await langfuse.fetchTrace(specificTraceId);
            traceSelected = trace.data;
        } else {
            // ê°€ì¥ ìµœê·¼ê²ƒ í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¨ë‹¤.!
            const traces = await langfuse.fetchTraces({
                name,
                userId,
            });
            traceSelected = traces.data[0];
        }

        if (!traceSelected) {
            return NextResponse.json(
                { error: 'No trace found' },
                { status: 404 },
            );
        }

        allLatency = traceSelected.latency;
        startTime = formatTime(traceSelected.createdAt);
        endTime = formatTime(traceSelected.updatedAt);

        const traceId: string = traceSelected.id;
        const Observations: any = (
            await langfuse.fetchObservations({
                userId,
                traceId,
            })
        ).data;

        // ê°€ì¥ ìµœê·¼ì— ì‹¤í–‰ëœ ê²ƒ ë¶€í„° ì¶œë ¥ë¨
        for (const Observation of Observations) {
            // ğŸ’¥ ëª¨ë¸ ì¶”ê°€ë˜ë©´ ìˆ˜ì •í•´ì•¼ í•¨.ğŸ’¥
            if (Observation.type === 'GENERATION')
                if (Observation.model === llmModel[0]) {
                    // "claude-3-5-sonnet-2024"
                    llmLatency[0].push(Observation.latency / 1000); // ms -> s
                    llmInputTokenCount[0].push(Observation.promptTokens);
                    llmOutputTokenCount[0].push(Observation.completionTokens);
                    llmToktalTokenCount[0].push(Observation.totalTokens);
                    llmCallCount[0] += 1;
                } else if (Observation.model === llmModel[1]) {
                    // "llama3.3"
                    llmLatency[1].push(Observation.latency / 1000); // ms -> s
                    llmInputTokenCount[1].push(Observation.promptTokens);
                    llmOutputTokenCount[1].push(Observation.completionTokens);
                    llmToktalTokenCount[1].push(Observation.totalTokens);
                    llmCallCount[1] += 1;
                    // console.log('Observation: ', Observation);
                } else {
                }
        }
        console.log(llmLatency);
        console.log(llmInputTokenCount);
        console.log(llmOutputTokenCount);
        console.log(llmToktalTokenCount);
    } catch (error) {
        console.error('Error fetching trace data:', error);
        return NextResponse.json(
            { error: 'Failed to fetch trace data' },
            { status: 500 },
        );
    }

    const { slug } = await params;
    if (slug === 'time') {
        try {
            return NextResponse.json({ data: 'time' }, { status: 200 });
        } catch (error) {
            return NextResponse.json(
                { error: 'Failed to fetch trace time data' },
                { status: 500 },
            );
        }
    } else if (slug === 'token') {
        try {
            return NextResponse.json({ data: 'token' }, { status: 200 });
        } catch (error) {
            return NextResponse.json(
                { error: 'Failed to fetch trace token data' },
                { status: 500 },
            );
        }
    } else if (slug === 'call') {
        try {
            // result ê°€ ê°ì²´!
            const llmCallCountData = llmModel.reduce<LlmCallCountData>(
                (result: LlmCallCountData, name: string, index: number) => {
                    result[name] = llmCallCount[index];
                    return result;
                },
                {},
            );
            return NextResponse.json(llmCallCountData, { status: 200 });
        } catch (error) {
            return NextResponse.json(
                { error: 'Failed to fetch trace call data' },
                { status: 500 },
            );
        }
    } else if (slug === 'summary') {
        try {
            return NextResponse.json({ data: 'summary' }, { status: 200 });
        } catch (error) {
            return NextResponse.json(
                { error: 'Failed to fetch trace summary data' },
                { status: 500 },
            );
        }
    } else {
        return NextResponse.json(
            { error: 'Something is wrong' },
            { status: 400 },
        );
    }
}
